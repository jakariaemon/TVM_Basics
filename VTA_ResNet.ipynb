{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeiRi-zc0NuZ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/04b_TVM_Tutorial_VTA_ResNet.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zYyoeEJZzD"
      },
      "source": [
        "Please run the following block to ensure TVM is setup for this notebook, each notebook may have its own runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FgC9UcUfJZzE",
        "outputId": "8a245a36-99eb-445f-a961-9b80b1984bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://tvm-fcrc-binaries-7f775516ff9dfab922c304049f294cec/tvm.tar.gz...\n",
            "\\ [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "total 164\n",
            "drwxr-xr-x 21 root root  4096 Sep 23 08:21 .\n",
            "drwxr-xr-x  1 root root  4096 Sep 23 08:21 ..\n",
            "drwx------  8 root root  4096 Jun 11  2019 3rdparty\n",
            "drwx------ 12 root root  4096 Jun 11  2019 apps\n",
            "drwx------  3 root root  4096 Jun 12  2019 build\n",
            "drwx------  4 root root  4096 Jun 11  2019 cmake\n",
            "-rw-------  1 root root 10406 Jun 11  2019 CMakeLists.txt\n",
            "drwx------  6 root root  4096 Jun 11  2019 conda\n",
            "-rw-------  1 root root  5673 Jun 11  2019 CONTRIBUTORS.md\n",
            "drwx------  3 root root  4096 Jun 11  2019 docker\n",
            "drwx------ 11 root root  4096 Jun 11  2019 docs\n",
            "drwx------  4 root root  4096 Jun 11  2019 golang\n",
            "drwx------  3 root root  4096 Jun 11  2019 include\n",
            "-rw-------  1 root root 10542 Jun 11  2019 Jenkinsfile\n",
            "drwx------  6 root root  4096 Jun 11  2019 jvm\n",
            "-rw-------  1 root root 11357 Jun 11  2019 LICENSE\n",
            "-rw-------  1 root root  4267 Jun 11  2019 Makefile\n",
            "-rw-------  1 root root 10476 Jun 11  2019 NEWS.md\n",
            "drwx------  9 root root  4096 Jun 11  2019 nnvm\n",
            "-rw-------  1 root root    61 Jun 11  2019 NOTICE\n",
            "-rwx------  1 root root   374 Jun 11  2019 package.sh\n",
            "drwx------  3 root root  4096 Jun 11  2019 python\n",
            "-rw-------  1 root root  2705 Jun 11  2019 README.md\n",
            "drwx------  6 root root  4096 Jun 11  2019 rust\n",
            "drwx------ 14 root root  4096 Jun 11  2019 src\n",
            "drwx------  9 root root  4096 Jun 11  2019 tests\n",
            "drwx------  7 root root  4096 Jun 11  2019 topi\n",
            "drwx------  8 root root  4096 Jun 11  2019 tutorials\n",
            "-rw-------  1 root root  2902 Jun 11  2019 version.py\n",
            "drwx------ 11 root root  4096 Jun 11  2019 vta\n",
            "drwx------  2 root root  4096 Jun 11  2019 web\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1 MB 132 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Installing Dependencies ...\n",
            "deb https://dl.bintray.com/sbt/debian /\n",
            "Executing: /tmp/apt-key-gpghome.OuozB3eM5l/gpg.1.sh --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823\n",
            "gpg: key 99E82A75642AC823: public key \"sbt build tool <scalasbt@gmail.com>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Err:4 https://dl.bintray.com/sbt/debian  InRelease\n",
            "  502  Bad Gateway [IP: 52.34.230.170 443]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [92.1 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,161 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,545 kB]\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,108 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,202 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,322 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,080 kB]\n",
            "Fetched 16.2 MB in 4s (4,467 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Failed to fetch https://dl.bintray.com/sbt/debian/InRelease  502  Bad Gateway [IP: 52.34.230.170 443]\n",
            "W: Some index files failed to download. They have been ignored, or old ones used instead.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "clinfo is already the newest version (2.2.18.03.26-1).\n",
            "libtinfo-dev is already the newest version (6.1-1ubuntu1.18.04).\n",
            "libtinfo-dev set to manually installed.\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  llvm-6.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  binfmt-support libffi-dev llvm-6.0 llvm-6.0-dev llvm-6.0-runtime tree\n",
            "0 upgraded, 6 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 28.3 MB of archives.\n",
            "After this operation, 178 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 binfmt-support amd64 2.1.8-2 [51.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 llvm-6.0-runtime amd64 1:6.0-1ubuntu2 [200 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 llvm-6.0 amd64 1:6.0-1ubuntu2 [4,838 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libffi-dev amd64 3.2.1-8 [156 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 llvm-6.0-dev amd64 1:6.0-1ubuntu2 [23.0 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 28.3 MB in 3s (10.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package binfmt-support.\n",
            "(Reading database ... 155569 files and directories currently installed.)\n",
            "Preparing to unpack .../0-binfmt-support_2.1.8-2_amd64.deb ...\n",
            "Unpacking binfmt-support (2.1.8-2) ...\n",
            "Selecting previously unselected package llvm-6.0-runtime.\n",
            "Preparing to unpack .../1-llvm-6.0-runtime_1%3a6.0-1ubuntu2_amd64.deb ...\n",
            "Unpacking llvm-6.0-runtime (1:6.0-1ubuntu2) ...\n",
            "Selecting previously unselected package llvm-6.0.\n",
            "Preparing to unpack .../2-llvm-6.0_1%3a6.0-1ubuntu2_amd64.deb ...\n",
            "Unpacking llvm-6.0 (1:6.0-1ubuntu2) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../3-libffi-dev_3.2.1-8_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.2.1-8) ...\n",
            "Selecting previously unselected package llvm-6.0-dev.\n",
            "Preparing to unpack .../4-llvm-6.0-dev_1%3a6.0-1ubuntu2_amd64.deb ...\n",
            "Unpacking llvm-6.0-dev (1:6.0-1ubuntu2) ...\n",
            "Selecting previously unselected package tree.\n",
            "Preparing to unpack .../5-tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up binfmt-support (2.1.8-2) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/binfmt-support.service → /lib/systemd/system/binfmt-support.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Setting up libffi-dev:amd64 (3.2.1-8) ...\n",
            "Setting up llvm-6.0-runtime (1:6.0-1ubuntu2) ...\n",
            "Setting up llvm-6.0 (1:6.0-1ubuntu2) ...\n",
            "Setting up llvm-6.0-dev (1:6.0-1ubuntu2) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.56) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package sbt\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    ! gsutil cp \"gs://tvm-fcrc-binaries-7f775516ff9dfab922c304049f294cec/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
        "    ! mkdir -p /tvm\n",
        "    ! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
        "    ! ls -la /tvm\n",
        "    ! pip install mxnet\n",
        "    ! bash /tvm/package.sh\n",
        "    # Add TVM to the Python path.\n",
        "    import sys\n",
        "    sys.path.append('/tvm/python')\n",
        "    sys.path.append('/tvm/topi/python')\n",
        "    sys.path.append('/tvm/nnvm/python')\n",
        "    sys.path.append('/tvm/vta/python')\n",
        "else:\n",
        "    print(\"Notebook executing locally, skipping Colab setup ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq9h0zoIJZzG"
      },
      "source": [
        "\n",
        "Deploy Pretrained ResNet Model from MxNet on VTA\n",
        "================================================\n",
        "**Author**: [Thierry Moreau](https://homes.cs.washington.edu/~moreau/)\n",
        "\n",
        "This tutorial provides an end-to-end demo, on how to run ResNet-18 inference\n",
        "onto the VTA accelerator design to perform ImageNet classification tasks.\n",
        "It showcases Relay as a front end compiler that can perform quantization (VTA only supports int8/32 inference) as well as graph packing (in order to enable tensorization in the core) to massage the compute graph for the hardware target.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9jy_y2UJZzH"
      },
      "source": [
        "Import packages\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T4v-vWA0JZzH"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "import argparse, json, os, requests, time\n",
        "from io import BytesIO\n",
        "from os.path import join, isfile\n",
        "from PIL import Image\n",
        "\n",
        "from mxnet.gluon.model_zoo import vision\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tvm\n",
        "from tvm import rpc, autotvm, relay\n",
        "from tvm.contrib import graph_runtime, util, download\n",
        "from tvm.contrib.debugger import debug_runtime\n",
        "\n",
        "import vta\n",
        "from vta.testing import simulator\n",
        "from vta.top import graph_pack\n",
        "\n",
        "# Make sure that TVM was compiled with RPC=1\n",
        "assert tvm.module.enabled(\"rpc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jJbYIp9JZzI"
      },
      "source": [
        "Define the platform and model targets\n",
        "-------------------------------------\n",
        "Execute on CPU vs. VTA, and define the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D0bBn499JZzI",
        "outputId": "97d144e9-0359-4b51-ebe6-f82372fc14ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim\n"
          ]
        }
      ],
      "source": [
        "# Load VTA parameters from the vta/config/vta_config.json file\n",
        "env = vta.get_env()\n",
        "print(env.TARGET)\n",
        "\n",
        "# Set device=arm_cpu to run inference on the CPU\n",
        "# or device=vta to run inference on the FPGA.\n",
        "device = \"vta\"\n",
        "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
        "\n",
        "# Name of Gluon model to compile\n",
        "model = \"resnet18_v1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo01ogQUJZzJ"
      },
      "source": [
        "Obtain an execution remote\n",
        "---------------------------------\n",
        "When target is `pynq`, reconfigure FPGA and runtime.\n",
        "Otherwise, if target is `sim`, execute locally.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QtLTzMS4JZzJ"
      },
      "outputs": [],
      "source": [
        "if env.TARGET != \"sim\":\n",
        "    \n",
        "    # Get remote to board\n",
        "    device_host = os.environ.get(\"VTA_PYNQ_RPC_HOST\", \"192.168.2.99\")\n",
        "    device_port = int(os.environ.get(\"VTA_PYNQ_RPC_PORT\", \"9091\"))\n",
        "    remote = rpc.connect(device_host, device_port)\n",
        "\n",
        "    # Reconfigure the JIT runtime and FPGA.\n",
        "    # You can program the FPGA with your own custom bitstream\n",
        "    # by passing the path to the bitstream file instead of None.\n",
        "    vta.reconfig_runtime(remote)\n",
        "    vta.program_fpga(remote, bitstream=None)\n",
        "\n",
        "# In simulation mode, host the RPC server locally.\n",
        "else:\n",
        "    remote = rpc.LocalSession()\n",
        "\n",
        "# Get execution context from remote\n",
        "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysgJc2npJZzK"
      },
      "source": [
        "Build the inference graph runtime\n",
        "---------------------------------\n",
        "Grab ResNet-18 model from Gluon model zoo and compile with Relay.\n",
        "The compilation steps are:\n",
        "   1. Front end translation from MxNet into Relay module.\n",
        "   2. Apply 8-bit quantization: here we skip the first conv layer,\n",
        "      and dense layer which will both be executed in fp32 on the CPU.\n",
        "   3. Perform graph packing to alter the data layout for tensorization.\n",
        "   4. Perform constant folding to reduce number of operators (e.g. eliminate batch norm multiply).\n",
        "   5. Perform relay build to object file.\n",
        "   6. Load the object file onto remote (FPGA device).\n",
        "   7. Generate graph runtime, `m`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n5qFlUVqJZzL",
        "outputId": "24cfc1b8-6029-491e-f3ce-0d757bfc367b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/models/resnet18_v1-a0666292.zip3f7fa4d8-fc3f-418f-b7c0-cfb2d7815e38 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1-a0666292.zip...\n",
            "v0.0.1\n",
            "fn (%data: Tensor[(1, 3, 224, 224), float32], %resnetv10_conv0_weight: Tensor[(64, 3, 7, 7), float32], %resnetv10_batchnorm0_gamma: Tensor[(64,), float32], %resnetv10_batchnorm0_beta: Tensor[(64,), float32], %resnetv10_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv10_batchnorm0_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv0_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm0_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm1_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm2_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv3_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm3_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_running_var: Tensor[(64,), float32], %resnetv10_stage2_conv2_weight: Tensor[(128, 64, 1, 1), float32], %resnetv10_stage2_batchnorm2_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv0_weight: Tensor[(128, 64, 3, 3), float32], %resnetv10_stage2_batchnorm0_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm1_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv3_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm3_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv4_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm4_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_running_var: Tensor[(128,), float32], %resnetv10_stage3_conv2_weight: Tensor[(256, 128, 1, 1), float32], %resnetv10_stage3_batchnorm2_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv0_weight: Tensor[(256, 128, 3, 3), float32], %resnetv10_stage3_batchnorm0_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv1_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm1_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv3_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm3_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv4_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm4_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_running_var: Tensor[(256,), float32], %resnetv10_stage4_conv2_weight: Tensor[(512, 256, 1, 1), float32], %resnetv10_stage4_batchnorm2_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv0_weight: Tensor[(512, 256, 3, 3), float32], %resnetv10_stage4_batchnorm0_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv1_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm1_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv3_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm3_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv4_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm4_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_running_var: Tensor[(512,), float32], %resnetv10_dense0_weight: Tensor[(1000, 512), float32], %resnetv10_dense0_bias: Tensor[(1000,), float32]) {\n",
            "  %0 = nn.conv2d(%data, %resnetv10_conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
            "  %1 = nn.batch_norm(%0, %resnetv10_batchnorm0_gamma, %resnetv10_batchnorm0_beta, %resnetv10_batchnorm0_running_mean, %resnetv10_batchnorm0_running_var)\n",
            "  %2 = %1.0\n",
            "  %3 = nn.relu(%2)\n",
            "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
            "  %5 = nn.conv2d(%4, %resnetv10_stage1_conv0_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
            "  %6 = nn.batch_norm(%5, %resnetv10_stage1_batchnorm0_gamma, %resnetv10_stage1_batchnorm0_beta, %resnetv10_stage1_batchnorm0_running_mean, %resnetv10_stage1_batchnorm0_running_var)\n",
            "  %7 = %6.0\n",
            "  %8 = nn.relu(%7)\n",
            "  %9 = nn.conv2d(%8, %resnetv10_stage1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
            "  %10 = nn.batch_norm(%9, %resnetv10_stage1_batchnorm1_gamma, %resnetv10_stage1_batchnorm1_beta, %resnetv10_stage1_batchnorm1_running_mean, %resnetv10_stage1_batchnorm1_running_var)\n",
            "  %11 = %10.0\n",
            "  %12 = add(%4, %11)\n",
            "  %13 = nn.relu(%12)\n",
            "  %14 = nn.conv2d(%13, %resnetv10_stage1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
            "  %15 = nn.batch_norm(%14, %resnetv10_stage1_batchnorm2_gamma, %resnetv10_stage1_batchnorm2_beta, %resnetv10_stage1_batchnorm2_running_mean, %resnetv10_stage1_batchnorm2_running_var)\n",
            "  %16 = %15.0\n",
            "  %17 = nn.relu(%16)\n",
            "  %18 = nn.conv2d(%17, %resnetv10_stage1_conv3_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
            "  %19 = nn.batch_norm(%18, %resnetv10_stage1_batchnorm3_gamma, %resnetv10_stage1_batchnorm3_beta, %resnetv10_stage1_batchnorm3_running_mean, %resnetv10_stage1_batchnorm3_running_var)\n",
            "  %20 = %19.0\n",
            "  %21 = add(%13, %20)\n",
            "  %22 = nn.relu(%21)\n",
            "  %23 = nn.conv2d(%22, %resnetv10_stage2_conv2_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
            "  %24 = nn.batch_norm(%23, %resnetv10_stage2_batchnorm2_gamma, %resnetv10_stage2_batchnorm2_beta, %resnetv10_stage2_batchnorm2_running_mean, %resnetv10_stage2_batchnorm2_running_var)\n",
            "  %25 = %24.0\n",
            "  %26 = nn.conv2d(%22, %resnetv10_stage2_conv0_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
            "  %27 = nn.batch_norm(%26, %resnetv10_stage2_batchnorm0_gamma, %resnetv10_stage2_batchnorm0_beta, %resnetv10_stage2_batchnorm0_running_mean, %resnetv10_stage2_batchnorm0_running_var)\n",
            "  %28 = %27.0\n",
            "  %29 = nn.relu(%28)\n",
            "  %30 = nn.conv2d(%29, %resnetv10_stage2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
            "  %31 = nn.batch_norm(%30, %resnetv10_stage2_batchnorm1_gamma, %resnetv10_stage2_batchnorm1_beta, %resnetv10_stage2_batchnorm1_running_mean, %resnetv10_stage2_batchnorm1_running_var)\n",
            "  %32 = %31.0\n",
            "  %33 = add(%25, %32)\n",
            "  %34 = nn.relu(%33)\n",
            "  %35 = nn.conv2d(%34, %resnetv10_stage2_conv3_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
            "  %36 = nn.batch_norm(%35, %resnetv10_stage2_batchnorm3_gamma, %resnetv10_stage2_batchnorm3_beta, %resnetv10_stage2_batchnorm3_running_mean, %resnetv10_stage2_batchnorm3_running_var)\n",
            "  %37 = %36.0\n",
            "  %38 = nn.relu(%37)\n",
            "  %39 = nn.conv2d(%38, %resnetv10_stage2_conv4_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
            "  %40 = nn.batch_norm(%39, %resnetv10_stage2_batchnorm4_gamma, %resnetv10_stage2_batchnorm4_beta, %resnetv10_stage2_batchnorm4_running_mean, %resnetv10_stage2_batchnorm4_running_var)\n",
            "  %41 = %40.0\n",
            "  %42 = add(%34, %41)\n",
            "  %43 = nn.relu(%42)\n",
            "  %44 = nn.conv2d(%43, %resnetv10_stage3_conv2_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
            "  %45 = nn.batch_norm(%44, %resnetv10_stage3_batchnorm2_gamma, %resnetv10_stage3_batchnorm2_beta, %resnetv10_stage3_batchnorm2_running_mean, %resnetv10_stage3_batchnorm2_running_var)\n",
            "  %46 = %45.0\n",
            "  %47 = nn.conv2d(%43, %resnetv10_stage3_conv0_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
            "  %48 = nn.batch_norm(%47, %resnetv10_stage3_batchnorm0_gamma, %resnetv10_stage3_batchnorm0_beta, %resnetv10_stage3_batchnorm0_running_mean, %resnetv10_stage3_batchnorm0_running_var)\n",
            "  %49 = %48.0\n",
            "  %50 = nn.relu(%49)\n",
            "  %51 = nn.conv2d(%50, %resnetv10_stage3_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
            "  %52 = nn.batch_norm(%51, %resnetv10_stage3_batchnorm1_gamma, %resnetv10_stage3_batchnorm1_beta, %resnetv10_stage3_batchnorm1_running_mean, %resnetv10_stage3_batchnorm1_running_var)\n",
            "  %53 = %52.0\n",
            "  %54 = add(%46, %53)\n",
            "  %55 = nn.relu(%54)\n",
            "  %56 = nn.conv2d(%55, %resnetv10_stage3_conv3_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
            "  %57 = nn.batch_norm(%56, %resnetv10_stage3_batchnorm3_gamma, %resnetv10_stage3_batchnorm3_beta, %resnetv10_stage3_batchnorm3_running_mean, %resnetv10_stage3_batchnorm3_running_var)\n",
            "  %58 = %57.0\n",
            "  %59 = nn.relu(%58)\n",
            "  %60 = nn.conv2d(%59, %resnetv10_stage3_conv4_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
            "  %61 = nn.batch_norm(%60, %resnetv10_stage3_batchnorm4_gamma, %resnetv10_stage3_batchnorm4_beta, %resnetv10_stage3_batchnorm4_running_mean, %resnetv10_stage3_batchnorm4_running_var)\n",
            "  %62 = %61.0\n",
            "  %63 = add(%55, %62)\n",
            "  %64 = nn.relu(%63)\n",
            "  %65 = nn.conv2d(%64, %resnetv10_stage4_conv2_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
            "  %66 = nn.batch_norm(%65, %resnetv10_stage4_batchnorm2_gamma, %resnetv10_stage4_batchnorm2_beta, %resnetv10_stage4_batchnorm2_running_mean, %resnetv10_stage4_batchnorm2_running_var)\n",
            "  %67 = %66.0\n",
            "  %68 = nn.conv2d(%64, %resnetv10_stage4_conv0_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
            "  %69 = nn.batch_norm(%68, %resnetv10_stage4_batchnorm0_gamma, %resnetv10_stage4_batchnorm0_beta, %resnetv10_stage4_batchnorm0_running_mean, %resnetv10_stage4_batchnorm0_running_var)\n",
            "  %70 = %69.0\n",
            "  %71 = nn.relu(%70)\n",
            "  %72 = nn.conv2d(%71, %resnetv10_stage4_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
            "  %73 = nn.batch_norm(%72, %resnetv10_stage4_batchnorm1_gamma, %resnetv10_stage4_batchnorm1_beta, %resnetv10_stage4_batchnorm1_running_mean, %resnetv10_stage4_batchnorm1_running_var)\n",
            "  %74 = %73.0\n",
            "  %75 = add(%67, %74)\n",
            "  %76 = nn.relu(%75)\n",
            "  %77 = nn.conv2d(%76, %resnetv10_stage4_conv3_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
            "  %78 = nn.batch_norm(%77, %resnetv10_stage4_batchnorm3_gamma, %resnetv10_stage4_batchnorm3_beta, %resnetv10_stage4_batchnorm3_running_mean, %resnetv10_stage4_batchnorm3_running_var)\n",
            "  %79 = %78.0\n",
            "  %80 = nn.relu(%79)\n",
            "  %81 = nn.conv2d(%80, %resnetv10_stage4_conv4_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
            "  %82 = nn.batch_norm(%81, %resnetv10_stage4_batchnorm4_gamma, %resnetv10_stage4_batchnorm4_beta, %resnetv10_stage4_batchnorm4_running_mean, %resnetv10_stage4_batchnorm4_running_var)\n",
            "  %83 = %82.0\n",
            "  %84 = add(%76, %83)\n",
            "  %85 = nn.relu(%84)\n",
            "  %86 = nn.global_avg_pool2d(%85)\n",
            "  %87 = nn.batch_flatten(%86)\n",
            "  %88 = nn.dense(%87, %resnetv10_dense0_weight, units=1000)\n",
            "  nn.bias_add(%88, %resnetv10_dense0_bias, axis=-1)\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Populate the shape and data type dictionary for ResNet input\n",
        "dtype_dict = {\"data\": 'float32'}\n",
        "shape_dict = {\"data\": (env.BATCH, 3, 224, 224)}\n",
        "\n",
        "# Get off the shelf gluon model, and convert to relay\n",
        "gluon_model = vision.get_model(model, pretrained=True)\n",
        "\n",
        "# Start front end compilation\n",
        "relay_prog, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
        "\n",
        "# Update shape and type dictionary\n",
        "shape_dict.update({k: v.shape for k, v in params.items()})\n",
        "dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
        "\n",
        "# Print the off the shelf model\n",
        "print(relay_prog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uLaZjj3mJZzL",
        "outputId": "dc04b1b4-34db-48f9-ff40-adb92440762c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v0.0.1\n",
            "fn (%data: Tensor[(1, 3, 224, 224), float32]) -> Tensor[(1, 1000), float32] {\n",
            "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */ /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
            "  %1 = add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
            "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
            "  %3 = nn.max_pool2d(%2, pool_size=[3, 3], strides=[2, 2], padding=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %4 = reshape(%3, newshape=[1, 1, 4, 16, 56, 56]) /* ty=Tensor[(1, 1, 4, 16, 56, 56), float32] */\n",
            "  %5 = transpose(%4, axes=[0, 2, 4, 5, 1, 3]) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %6 = multiply(%5, 16f /* ty=float32 */) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %7 = round(%6) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %8 = clip(%7, a_min=-127, a_max=127) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %9 = cast(%8, dtype=\"int8\") /* ty=Tensor[(1, 4, 56, 56, 1, 16), int8] */\n",
            "  %10 = multiply(%5, 16f /* ty=float32 */) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %11 = round(%10) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %12 = clip(%11, a_min=-127, a_max=127) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
            "  %13 = cast(%12, dtype=\"int8\") /* ty=Tensor[(1, 4, 56, 56, 1, 16), int8] */\n",
            "  %14 = nn.conv2d(%13, meta[relay.Constant][2], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %15 = add(%14, meta[relay.Constant][3])\n",
            "  %16 = nn.relu(%15)\n",
            "  %17 = add(%16, 64 /* ty=int32 */)\n",
            "  %18 = right_shift(%17, 7 /* ty=int32 */)\n",
            "  %19 = clip(%18, a_min=-127, a_max=127)\n",
            "  %20 = cast(%19, dtype=\"int8\")\n",
            "  %21 = copy(%20)\n",
            "  %22 = stop_fusion(%21)\n",
            "  %23 = nn.conv2d(%22, meta[relay.Constant][4], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %24 = add(%23, meta[relay.Constant][5])\n",
            "  %25 = add(%24, 32 /* ty=int32 */)\n",
            "  %26 = right_shift(%25, 6 /* ty=int32 */)\n",
            "  %27 = clip(%26, a_min=-127, a_max=127)\n",
            "  %28 = cast(%27, dtype=\"int8\")\n",
            "  %29 = copy(%28)\n",
            "  %30 = stop_fusion(%29)\n",
            "  %31 = add(%9, %30)\n",
            "  %32 = nn.relu(%31)\n",
            "  %33 = cast(%32, dtype=\"int8\")\n",
            "  %34 = cast(%32, dtype=\"int8\")\n",
            "  %35 = nn.conv2d(%34, meta[relay.Constant][6], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %36 = add(%35, meta[relay.Constant][7])\n",
            "  %37 = nn.relu(%36)\n",
            "  %38 = add(%37, 256 /* ty=int32 */)\n",
            "  %39 = right_shift(%38, 9 /* ty=int32 */)\n",
            "  %40 = clip(%39, a_min=-127, a_max=127)\n",
            "  %41 = cast(%40, dtype=\"int8\")\n",
            "  %42 = copy(%41)\n",
            "  %43 = stop_fusion(%42)\n",
            "  %44 = nn.conv2d(%43, meta[relay.Constant][8], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %45 = add(%44, meta[relay.Constant][9])\n",
            "  %46 = add(%45, 32 /* ty=int32 */)\n",
            "  %47 = right_shift(%46, 6 /* ty=int32 */)\n",
            "  %48 = clip(%47, a_min=-127, a_max=127)\n",
            "  %49 = cast(%48, dtype=\"int8\")\n",
            "  %50 = copy(%49)\n",
            "  %51 = stop_fusion(%50)\n",
            "  %52 = add(%33, %51)\n",
            "  %53 = nn.relu(%52)\n",
            "  %54 = cast(%53, dtype=\"int8\")\n",
            "  %55 = nn.conv2d(%54, meta[relay.Constant][10], strides=[2, 2], channels=128, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %56 = add(%55, meta[relay.Constant][11])\n",
            "  %57 = add(%56, 64 /* ty=int32 */)\n",
            "  %58 = right_shift(%57, 7 /* ty=int32 */)\n",
            "  %59 = clip(%58, a_min=-127, a_max=127)\n",
            "  %60 = cast(%59, dtype=\"int8\")\n",
            "  %61 = copy(%60)\n",
            "  %62 = stop_fusion(%61)\n",
            "  %63 = cast(%62, dtype=\"int8\")\n",
            "  %64 = cast(%53, dtype=\"int8\")\n",
            "  %65 = nn.conv2d(%64, meta[relay.Constant][12], strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %66 = add(%65, meta[relay.Constant][13])\n",
            "  %67 = nn.relu(%66)\n",
            "  %68 = add(%67, 256 /* ty=int32 */)\n",
            "  %69 = right_shift(%68, 9 /* ty=int32 */)\n",
            "  %70 = clip(%69, a_min=-127, a_max=127)\n",
            "  %71 = cast(%70, dtype=\"int8\")\n",
            "  %72 = copy(%71)\n",
            "  %73 = stop_fusion(%72)\n",
            "  %74 = nn.conv2d(%73, meta[relay.Constant][14], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %75 = add(%74, meta[relay.Constant][15])\n",
            "  %76 = add(%75, 64 /* ty=int32 */)\n",
            "  %77 = right_shift(%76, 7 /* ty=int32 */)\n",
            "  %78 = clip(%77, a_min=-127, a_max=127)\n",
            "  %79 = cast(%78, dtype=\"int8\")\n",
            "  %80 = copy(%79)\n",
            "  %81 = stop_fusion(%80)\n",
            "  %82 = add(%63, %81)\n",
            "  %83 = nn.relu(%82)\n",
            "  %84 = cast(%83, dtype=\"int8\")\n",
            "  %85 = cast(%83, dtype=\"int8\")\n",
            "  %86 = nn.conv2d(%85, meta[relay.Constant][16], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %87 = add(%86, meta[relay.Constant][17])\n",
            "  %88 = nn.relu(%87)\n",
            "  %89 = add(%88, 128 /* ty=int32 */)\n",
            "  %90 = right_shift(%89, 8 /* ty=int32 */)\n",
            "  %91 = clip(%90, a_min=-127, a_max=127)\n",
            "  %92 = cast(%91, dtype=\"int8\")\n",
            "  %93 = copy(%92)\n",
            "  %94 = stop_fusion(%93)\n",
            "  %95 = nn.conv2d(%94, meta[relay.Constant][18], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %96 = add(%95, meta[relay.Constant][19])\n",
            "  %97 = add(%96, 64 /* ty=int32 */)\n",
            "  %98 = right_shift(%97, 7 /* ty=int32 */)\n",
            "  %99 = clip(%98, a_min=-127, a_max=127)\n",
            "  %100 = cast(%99, dtype=\"int8\")\n",
            "  %101 = copy(%100)\n",
            "  %102 = stop_fusion(%101)\n",
            "  %103 = add(%84, %102)\n",
            "  %104 = nn.relu(%103)\n",
            "  %105 = cast(%104, dtype=\"int8\")\n",
            "  %106 = nn.conv2d(%105, meta[relay.Constant][20], strides=[2, 2], channels=256, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %107 = add(%106, meta[relay.Constant][21])\n",
            "  %108 = add(%107, 128 /* ty=int32 */)\n",
            "  %109 = right_shift(%108, 8 /* ty=int32 */)\n",
            "  %110 = clip(%109, a_min=-127, a_max=127)\n",
            "  %111 = cast(%110, dtype=\"int8\")\n",
            "  %112 = copy(%111)\n",
            "  %113 = stop_fusion(%112)\n",
            "  %114 = cast(%113, dtype=\"int8\")\n",
            "  %115 = cast(%104, dtype=\"int8\")\n",
            "  %116 = nn.conv2d(%115, meta[relay.Constant][22], strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %117 = add(%116, meta[relay.Constant][23])\n",
            "  %118 = nn.relu(%117)\n",
            "  %119 = add(%118, 256 /* ty=int32 */)\n",
            "  %120 = right_shift(%119, 9 /* ty=int32 */)\n",
            "  %121 = clip(%120, a_min=-127, a_max=127)\n",
            "  %122 = cast(%121, dtype=\"int8\")\n",
            "  %123 = copy(%122)\n",
            "  %124 = stop_fusion(%123)\n",
            "  %125 = nn.conv2d(%124, meta[relay.Constant][24], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %126 = add(%125, meta[relay.Constant][25])\n",
            "  %127 = add(%126, 64 /* ty=int32 */)\n",
            "  %128 = right_shift(%127, 7 /* ty=int32 */)\n",
            "  %129 = clip(%128, a_min=-127, a_max=127)\n",
            "  %130 = cast(%129, dtype=\"int8\")\n",
            "  %131 = copy(%130)\n",
            "  %132 = stop_fusion(%131)\n",
            "  %133 = add(%114, %132)\n",
            "  %134 = nn.relu(%133)\n",
            "  %135 = cast(%134, dtype=\"int8\")\n",
            "  %136 = cast(%134, dtype=\"int8\")\n",
            "  %137 = nn.conv2d(%136, meta[relay.Constant][26], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %138 = add(%137, meta[relay.Constant][27])\n",
            "  %139 = nn.relu(%138)\n",
            "  %140 = add(%139, 128 /* ty=int32 */)\n",
            "  %141 = right_shift(%140, 8 /* ty=int32 */)\n",
            "  %142 = clip(%141, a_min=-127, a_max=127)\n",
            "  %143 = cast(%142, dtype=\"int8\")\n",
            "  %144 = copy(%143)\n",
            "  %145 = stop_fusion(%144)\n",
            "  %146 = nn.conv2d(%145, meta[relay.Constant][28], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %147 = add(%146, meta[relay.Constant][29])\n",
            "  %148 = add(%147, 64 /* ty=int32 */)\n",
            "  %149 = right_shift(%148, 7 /* ty=int32 */)\n",
            "  %150 = clip(%149, a_min=-127, a_max=127)\n",
            "  %151 = cast(%150, dtype=\"int8\")\n",
            "  %152 = copy(%151)\n",
            "  %153 = stop_fusion(%152)\n",
            "  %154 = add(%135, %153)\n",
            "  %155 = nn.relu(%154)\n",
            "  %156 = cast(%155, dtype=\"int8\")\n",
            "  %157 = nn.conv2d(%156, meta[relay.Constant][30], strides=[2, 2], channels=512, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %158 = add(%157, meta[relay.Constant][31])\n",
            "  %159 = add(%158, 32 /* ty=int32 */)\n",
            "  %160 = right_shift(%159, 6 /* ty=int32 */)\n",
            "  %161 = clip(%160, a_min=-127, a_max=127)\n",
            "  %162 = cast(%161, dtype=\"int8\")\n",
            "  %163 = copy(%162)\n",
            "  %164 = stop_fusion(%163)\n",
            "  %165 = cast(%164, dtype=\"int8\")\n",
            "  %166 = cast(%155, dtype=\"int8\")\n",
            "  %167 = nn.conv2d(%166, meta[relay.Constant][32], strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %168 = add(%167, meta[relay.Constant][33])\n",
            "  %169 = nn.relu(%168)\n",
            "  %170 = add(%169, 128 /* ty=int32 */)\n",
            "  %171 = right_shift(%170, 8 /* ty=int32 */)\n",
            "  %172 = clip(%171, a_min=-127, a_max=127)\n",
            "  %173 = cast(%172, dtype=\"int8\")\n",
            "  %174 = copy(%173)\n",
            "  %175 = stop_fusion(%174)\n",
            "  %176 = nn.conv2d(%175, meta[relay.Constant][34], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %177 = add(%176, meta[relay.Constant][35])\n",
            "  %178 = add(%177, 32 /* ty=int32 */)\n",
            "  %179 = right_shift(%178, 6 /* ty=int32 */)\n",
            "  %180 = clip(%179, a_min=-127, a_max=127)\n",
            "  %181 = cast(%180, dtype=\"int8\")\n",
            "  %182 = copy(%181)\n",
            "  %183 = stop_fusion(%182)\n",
            "  %184 = add(%165, %183)\n",
            "  %185 = nn.relu(%184)\n",
            "  %186 = cast(%185, dtype=\"int8\")\n",
            "  %187 = cast(%185, dtype=\"int8\")\n",
            "  %188 = nn.conv2d(%187, meta[relay.Constant][36], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %189 = add(%188, meta[relay.Constant][37])\n",
            "  %190 = nn.relu(%189)\n",
            "  %191 = add(%190, 128 /* ty=int32 */)\n",
            "  %192 = right_shift(%191, 8 /* ty=int32 */)\n",
            "  %193 = clip(%192, a_min=-127, a_max=127)\n",
            "  %194 = cast(%193, dtype=\"int8\")\n",
            "  %195 = copy(%194)\n",
            "  %196 = stop_fusion(%195)\n",
            "  %197 = nn.conv2d(%196, meta[relay.Constant][38], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
            "  %198 = add(%197, meta[relay.Constant][39])\n",
            "  %199 = add(%198, 8 /* ty=int32 */)\n",
            "  %200 = right_shift(%199, 4 /* ty=int32 */)\n",
            "  %201 = clip(%200, a_min=-127, a_max=127)\n",
            "  %202 = cast(%201, dtype=\"int8\")\n",
            "  %203 = copy(%202)\n",
            "  %204 = stop_fusion(%203)\n",
            "  %205 = add(%186, %204)\n",
            "  %206 = nn.relu(%205)\n",
            "  %207 = cast(%206, dtype=\"int8\")\n",
            "  %208 = cast(%207, dtype=\"float32\")\n",
            "  %209 = multiply(%208, 0.0625f /* ty=float32 */)\n",
            "  %210 = transpose(%209, axes=[0, 4, 1, 5, 2, 3])\n",
            "  %211 = reshape(%210, newshape=[1, 512, 7, 7])\n",
            "  %212 = nn.global_avg_pool2d(%211)\n",
            "  %213 = nn.batch_flatten(%212)\n",
            "  %214 = nn.dense(%213, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */ /* ty=Tensor[(1000, 512), float32] */, units=1000)\n",
            "  add(%214, meta[relay.Constant][41] /* ty=Tensor[(1000,), float32] */ /* ty=Tensor[(1000,), float32] */)\n",
            "}\n",
            "// meta data omitted. you can use show_meta_data=True to include meta data\n"
          ]
        }
      ],
      "source": [
        "# Perform quantization in Relay\n",
        "with relay.quantize.qconfig(global_scale=8.0,\n",
        "                            skip_k_conv=1,\n",
        "                            skip_k_dense=1,\n",
        "                            target_vta=True):\n",
        "    relay_prog = relay.quantize.quantize(relay_prog, params=params)\n",
        "\n",
        "# Perform graph packing and constant folding for VTA target\n",
        "if target.device_name == \"vta\":\n",
        "    assert env.BLOCK_IN == env.BLOCK_OUT\n",
        "    relay_prog = graph_pack(\n",
        "        relay_prog,\n",
        "        env.BATCH,\n",
        "        env.BLOCK_OUT,\n",
        "        env.WGT_WIDTH,\n",
        "        start_name=\"nn.max_pool2d\",\n",
        "        stop_name=\"nn.global_avg_pool2d\")\n",
        "    relay_prog = relay.ir_pass.fold_constant(relay_prog)\n",
        "\n",
        "# Print the transformed model\n",
        "print(relay_prog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2AZfOvh0JZzL",
        "outputId": "8502aa43-f27c-42c8-fee9-c9f0817150e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...100%, 0.03 MB, 147 KB/s, 0 seconds passed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autotvm:Cannot find config for target=ext_dev -device=vta -keys=cpu -model=sim, workload=('dense', (1, 512, 'float32'), (1000, 512, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
          ]
        }
      ],
      "source": [
        "# Graph runtime\n",
        "m = None\n",
        "\n",
        "# Load pre-configured AutoTVM schedules\n",
        "with autotvm.tophub.context(target):\n",
        "    \n",
        "    # Compile Relay program with AlterOpLayout disabled\n",
        "    with relay.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
        "        if target.device_name != \"vta\":\n",
        "            graph, lib, params = relay.build(\n",
        "                relay_prog, target=target,\n",
        "                params=params, target_host=env.target_host)\n",
        "        else:\n",
        "            with vta.build_config():\n",
        "                graph, lib, params = relay.build(\n",
        "                    relay_prog, target=target,\n",
        "                    params=params, target_host=env.target_host)\n",
        "\n",
        "    # Send the inference library over to the remote RPC server\n",
        "    temp = util.tempdir()\n",
        "    lib.save(temp.relpath(\"graphlib.o\"))\n",
        "    remote.upload(temp.relpath(\"graphlib.o\"))\n",
        "    lib = remote.load_module(\"graphlib.o\")\n",
        "\n",
        "    # Graph runtime\n",
        "    if env.TARGET == \"sim\":\n",
        "        m = graph_runtime.create(graph, lib, ctx)\n",
        "    elif env.TARGET == \"pynq\":\n",
        "        # In hardware we'll use the debug runtime\n",
        "        from tvm.contrib.debugger import debug_runtime\n",
        "        m = debug_runtime.create(graph, lib, ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2QWBvFTJZzM"
      },
      "source": [
        "Perform ResNet-18 inference\n",
        "---------------------------\n",
        "We run classification on an image sample from ImageNet\n",
        "We just need to download the categories files, `synset.txt`\n",
        "and an input test image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u8DkjMl1JZzM",
        "outputId": "e3aa3f89-4ece-4757-c493-1ee8a6c57b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from url https://github.com/uwsaml/web-data/raw/master/vta/models/synset.txt to synset.txt\n",
            "download failed due to <HTTPError 404: 'Not Found'>, retrying, 2 attempts left\n",
            "download failed due to <HTTPError 404: 'Not Found'>, retrying, 1 attempt left\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a57f34dabf80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcateg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/uwsaml/web-data/raw/master/vta/models/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcateg_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"synset.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcateg_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcateg_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcateg_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcateg_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tvm/python/tvm/contrib/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, path, overwrite, size_compare, verbose, retries)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 print(\"download failed due to {}, retrying, {} attempt{} left\"\n",
            "\u001b[0;32m/tvm/python/tvm/contrib/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, path, overwrite, size_compare, verbose, retries)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_download_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "# Download ImageNet categories\n",
        "categ_url = \"https://github.com/uwsaml/web-data/raw/master/vta/models/\"\n",
        "categ_fn = \"synset.txt\"\n",
        "download.download(join(categ_url, categ_fn), categ_fn)\n",
        "synset = eval(open(categ_fn).read())\n",
        "\n",
        "# Download test image\n",
        "image_url = 'https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg'\n",
        "response = requests.get(image_url)\n",
        "\n",
        "# Prepare test image for inference\n",
        "image = Image.open(BytesIO(response.content)).resize((224, 224))\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "image = np.array(image) - np.array([123., 117., 104.])\n",
        "image /= np.array([58.395, 57.12, 57.375])\n",
        "image = image.transpose((2, 0, 1))\n",
        "image = image[np.newaxis, :]\n",
        "image = np.repeat(image, env.BATCH, axis=0)\n",
        "\n",
        "# Set the network parameters and inputs\n",
        "m.set_input(**params)\n",
        "m.set_input('data', image)\n",
        "\n",
        "# Perform inference: we run the module 4 times,\n",
        "# and repeat 3 times to get error bounds\n",
        "timer = m.module.time_evaluator(\"run\", ctx, number=4, repeat=3)\n",
        "tcost = timer()\n",
        "\n",
        "# Get classification results\n",
        "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
        "top_categories = np.argsort(tvm_output.asnumpy()[0])\n",
        "\n",
        "# Report top-5 classification results\n",
        "std = np.std(tcost.results) * 1000 / env.BATCH\n",
        "mean = tcost.mean * 1000 / env.BATCH\n",
        "print(\"%s prediction\" % model)\n",
        "print(\"                     #1:\", synset[top_categories[-1]])\n",
        "print(\"                     #2:\", synset[top_categories[-2]])\n",
        "print(\"                     #3:\", synset[top_categories[-3]])\n",
        "print(\"                     #4:\", synset[top_categories[-4]])\n",
        "print(\"                     #5:\", synset[top_categories[-5]])\n",
        "print(\"Performed inference in %.2fms/sample (std = %.2f)\" % (mean, std))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fry9n36oJZzN"
      },
      "outputs": [],
      "source": [
        "# Invoke the debug runtime to get a per-operator runtime breakdown\n",
        "if env.TARGET == \"pynq\":\n",
        "    m.run()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}